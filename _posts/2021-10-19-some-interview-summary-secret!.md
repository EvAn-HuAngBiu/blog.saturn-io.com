---
layout: post
title: 一些基础问题汇总[未完成，加密]
categories: 问题
description: 对一些基础问题的总结和解答（暂未完成）
keywords: 问题,解答
---

#### Linux内存分页管理

Linux下进程不能直接访问物理内存，Linux下，进程通过访问虚拟内存，由操作系统负责将虚拟内存地址转换为物理内存地址来实现对物理内存的访问。每个进程都有自己的一套虚拟内存地址，用来给自己的进程空间编号。进程空间的数据同样以字节为单位，依次增加。

就是说在Linux中，如果进程想要访问内存信息，那么访问的地址会被操作系统审查，这个审查的步骤就是将虚拟内存地址转换为物理内存地址，从而由操作系统保证了进程的独立性；同时也方便了内存共享，只要将同一块物理内存区域映射到不同的虚拟内存上就可以很方便的实现内存共享。

Linux系统中，一页的长度为4K，对于一个4G内存的空间，它可以容纳1048576个页，也同时需要1048576个页表项，所以32位Linux系统使用内存地址的0到11位用来表示页号，而12到32位用来表示页内偏移。



#### 保证线程安全的手段

1. 互斥同步：即传统的利用锁的同步机制
2. 非阻塞同步：目的就是为了解决互斥同步中过度悲观的做法，无论有无竞争都尝试去加锁。加锁会带来以下开销：a. 线程上下文切换开销；b. 利用系统互斥量加锁会导致从用户态切换到内核态会产生开销；c. java线程是一一映射到内核线程上的，所以唤醒线程时需要借助内核，也会发生频繁的用户态和内核态的切换。典型解决方法：CAS、基于CAS实现的Atomic类
3. 无同步机制：同步只是在多线程访问共享数据时才会出现的问题，那么在**可重入代码**中，天生就不会出现线程不安全问题。（所谓可重入代码是指不依赖全局变量以及堆上变量以及公共的系统资源的代码，这类代码对于输入确定的参数，无论在什么情况下都有确定的返回值；或者使用ThreadLocal来保存线程独享的变量。



#### 锁消除、锁粗化

锁消除是指编译器会对代码进行逃逸分析，对于那些判定为不可能出现线程不安全现象的synchronized方法或代码块，会消除它们的锁；

锁粗化是指编译器发现对某段代码或对象进行频繁的加锁和解锁操作时，会将加锁范围扩大，以减少频繁的加锁和解锁操作。



#### 轻量级锁

轻量级锁的原理是在当前线程的栈帧中建立一个锁记录（Lock Record）空间，用于存储目前的Mark Word的拷贝，然后JVM使用CAS尝试将对象的Mark Word更新为指向Lock Record的指针，如果CAS更新成功了，则认为没有竞争，成功获取了锁，目前这个对象处于轻量级锁定状态。

如果竞争失败了，那么JVM会先检查是否是当前线程重入了锁，如果是，那么直接获取锁，计数器+1；如果不是说明存在锁竞争且有2个以上的线程竞争锁，那么轻量级锁会膨胀为重量级锁，此时的Mark Word就指向系统互斥量的指针，后面没有抢到锁的线程就要阻塞了。

解锁操作时，同样使用CAS将Lock Record保存的之前的Mark Word设置为当前Mark Word，如果设置成功，说明当前对象没有竞争；反之说明存在线程竞争，解锁的线程要负责唤醒阻塞的线程（此时已经膨胀为了重量级锁）。

理论依据：对于绝大多数锁，在其同步周期内都不存在竞争。

要注意：**当一个线程获取锁，另一个线程等待时，等待的线程不会阻塞、锁也不会膨胀，而是会使用自旋的方法来不断尝试获取锁，当自旋次数过多时才会导致锁膨胀**。

**缺点**：对单核处理器无效，依赖内核线程实现，一个线程自旋时另一个不可能释放锁；占用CPU；失败时反而比重量级锁浪费时间。

**自适应自旋锁**：如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也很有可能再次成功，进而它将允许自旋等待持续相对更长的时间，比如100个循环。相反的，如果对于某个锁，自旋很少成功获得过，那在以后要获取这个锁时将可能减少自旋时间甚至省略自旋过程，以避免浪费处理器资源。

轻量级锁适用于少量线程竞争的场景。



#### 偏向锁

在大多数情况下，锁很少被多个线程同时竞争，而且总是由同一个线程多次获得，因此只需要将获得锁的线程ID写入到锁对象Mark Word中，相当于告诉其他线程，这块资源已经被我占了。当线程访问资源结束后，不会主动释放偏向锁，当线程再次需要访问资源时，JVM就会通过Mark Word中记录的线程ID判断是否是当前线程，如果是，则继续访问资源。所以，在没有其他线程参与竞争时，锁就一直偏向被当前线程持有，当前线程就可以一直占用资源或者执行代码。

偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，线程不会主动去释放偏向锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，判断锁对象是否处于被锁定状态，撤销偏向锁后恢复到未锁定（标志位为“01”）或轻量级锁（标志位为“00”）的状态。

存在竞争的时候，在下一个全局安全点，偏向锁就会被撤销，然后给偏向锁的持有者加上轻量级锁；如果当前偏向锁的持有者没有加锁，那么并不是将其恢复到无锁状态，而是将偏向锁中的线程ID置空。**所以说偏向锁的撤销包含两种含义，一种就是偏向锁的持有线程还处于临界区内，偏向锁撤销然后升级为轻量级锁；另一种是偏向锁的持有线程退出了临界区，偏向锁撤销清空偏向线程ID，重新偏向新的线程**。

**特点：只适合在非常少、甚至没有竞争的场景，因为偏向锁的撤销非常耗时，需要在全局安全点遍历偏向线程的栈帧。它解决的问题是避免同一个线程重复获取锁带来的开销。**



#### 实模式和保护模式

二者指的是CPU的工作模式即CPU的寻址方式、寄存器大小等用来反应CPU在该环境下如何工作的概念：

CPU复位（reset）或加电（power on）的时候以实模式启动，处理器以实模式工作。在实模式下，内存寻址分为两个部分：（段基址:段内偏移），段基址来源于16位段寄存器，将16位段寄存器的值左移4位就是段基址了，将段基址和段内偏移相加构成的20位地址用于内存寻址。即：

　　物理地址 = 段基址<<4 + 段内偏移

假设段寄存器中的值是0xff00，段偏移量为0x0110。则这个地址对应的真实物理地址是 0xff00<<4 + 0x0110 = 0xff110。

**所以，实模式的"实"更多地体现在其地址是真实的物理地址。**同时，实模式下最大寻址位为2的20次幂，没有安全级别，不支持分页（没有虚拟地址的概念，只有物理地址）。



 在保护模式中，内存的管理模式分为两种——段模式和页模式。其中页模式也是基于段模式的。也就是说，保护模式的内存管理模式事实上是：纯段模式和段页式。进一步说，段模式是必不可少的，而页模式则是可选的——如果使用页模式，则是段页式，否则这是纯段模式。

假设在段模式下，访问一个内存地址依然使用（段基址:段内偏移）的方式，但是此时的段基址高13位指向了全局描述符GPT的基址，GDT描述的是段类型即段描述符，GDT中的每一个段都描述了一个内存段的基本属性

   为了改进实模式下内存访问的不安全性，保护模式给内存段添加了段属性来限制用户程序对内存的操作权限。保护模式引入了全局描述符表（Global Descriptor Table，GDT），GDT的表项是描述段类型属性的数据结构——段描述符。GDT中的每一个段描述符都描述了一个内存段的基本属性，如段基址、段界限、类型、特权级别等等。所以说此时对于（段基址:段内偏移）的结构而言，它不再直接访问物理内存，而是在GDT中间接寻找目标内存区域，此时进程在访问内存段（无论是数据段还是代码段）前都需要通过特权级检查。



#### TCP长连接和TCP保活机制

client向server发起连接，server接受client连接，双方建立连接。Client与server完成一次读写之后，它们之间的连接并不会主动关闭，后续的读写操作会继续使用这个连接。

TCP保活功能，保活功能主要为服务器应用提供，服务器应用希望知道客户主机是否崩溃，从而可以代表客户使用资源。如果客户已经消失，使得服务器上保留一个半开放的连接，而服务器又在等待来自客户端的数据，则服务器将应远等待客户端的数据，保活功能就是试图在服务器端检测到这种半开放的连接。（**即客户端中断了连接，但服务端不知道，保持在一个半开放状态了**）

如果一个给定的连接在两小时内没有任何的动作，则服务器就向客户发一个探测报文段，客户主机必须处于以下4个状态之一：

1. 客户主机依然正常运行，并从服务器可达。客户的TCP响应正常，而服务器也知道对方是正常的，服务器在两小时后将保活定时器复位。
2. 客户主机已经崩溃，并且关闭或者正在重新启动。在任何一种情况下，客户的TCP都没有响应。服务端将不能收到对探测的响应，并在75秒后超时。服务器总共发送10个这样的探测 ，每个间隔75秒。如果服务器没有收到一个响应，它就认为客户主机已经关闭并终止连接。
3. 客户主机崩溃并已经重新启动。服务器将收到一个对其保活探测的响应，这个响应是一个复位，使得服务器终止这个连接。
4. 客户机正常运行，但是服务器不可达，这种情况与2类似，TCP能发现的就是没有收到探查的响应。

从上面可以看出，TCP保活功能主要为探测长连接的存活状况，不过这里存在一个问题，存活功能的探测周期太长，还有就是它只是探测TCP连接的存活，属于比较斯文的做法，遇到恶意的连接时，保活功能就不够使了。

连接→数据传输→保持连接(心跳)→数据传输→保持连接(心跳)→……→关闭连接（一个TCP连接通道多个读写通信）； *

\*   这就要求长连接在没有数据通信时，定时发送数据包(心跳)，以维持连接状态；这个心跳包就是一个ACK=1的报文，不包含任何数据，也不受窗口控制。

这里要区别，TCP的Keepalive作用是保活，HTTP的Keep-Alive作用是复用TCP连接。



#### TCP和UDP

TCP是面向字节流的、可靠的、有连接的协议，UDP是面向报文的、不可靠、无连接、尽最大努力交付的连接。

典型的TCP应用：HTTP、FTP

典型的UDP应用：DNS、DHCP

面向字节流是指：虽然应用程序和TCP的交互是一次一个数据块（大小不等），但TCP把应用程序看成是一连串的无结构的字节流。TCP有一个缓冲，当应用程序传送的数据块太长，TCP就可以把它划分短一些再传送。如果应用程序一次只发送一个字节，TCP也可以等待积累有足够多的字节后再构成报文段发送出去。同时如果TCP协议收到乱序的数据会将其排序后交付给上层应用；

面向报文是指：应用层交给UDP多长的报文，UDP就照样发送，即一次发送一个报文。因此，应用程序必须选择合适大小的报文。若报文太长，则IP层需要分片，降低效率。若太短，会是IP太小。UDP对应用层交下来的报文，既不合并，也不拆分，而是保留这些报文的边界。这也就是说，应用层交给UDP多长的报文，UDP就照样发送，即一次发送一个报文。

|          |                  TCP                   |              UDP               |
| :------: | :------------------------------------: | :----------------------------: |
|  可靠性  |                  可靠                  |             不可靠             |
|  连接性  |                 有连接                 |             无连接             |
|   报文   |               面向字节流               |            面向报文            |
|   效率   |                   低                   |               高               |
|  双工性  |                 全双工                 | 一对一、一对多、多对一、多对多 |
| 流量控制 |             有（滑动窗口）             |               无               |
| 拥塞控制 | 有（慢开始、拥塞避免、快重传、快恢复） |               无               |



#### 为什么是三次握手而不是两次

1. 现而易见，三次握手可以检测服务端和客户端双方的发送和读取的能力。
2. 如果是两次握手，客户A向服务器B发送了一个连接请求，如果这个请求丢失，A等待计时器超时后会重传一个连接请求，此时服务器B收到请求并确认了建立，在这个过程中A和B完成了消息交互关闭连接，此时A第一次发送的建立连接请求到达了B，此时如果B返回一个确认连接建立请求并返回确认报文，而客户端A收到了一个莫名其妙的报文不知道怎么处理，而服务端却开启了连接，这会造成资源浪费。



#### TIME-WAIT和CLOSE-WAIT

CLOSE-WAIT是半关闭后，服务端所处的状态

TIME-WAIT是客户端响应关闭后需要等待2MSL时间，这段时间内客户端处于TIME-WAIT状态。需要持续2MSL的原因是，如果客户端响应服务端关闭的报文丢失会触发服务端的超时重传，如果此时客户端关闭了，那么服务端就会处于一个无法正常关闭的状态，浪费资源。等待2MSL也就是等待2倍的报文最长生存时间，这样可以保证客户端发送的响应到达服务端或者服务端超时重传的报文到达客户端。

如果网络中存在大量的TIME-WAIT，那么说明大量的服务器资源处在无法关闭的状态，对于服务器有很大的资源压力。

同时2MSL也保证了没有本次连接遗留的报文干扰下一次连接的建立。



#### 会话层

这一层也可以称为会晤层或对话层，在会话层及以上的高层次中，数据传送的单位不再另外命名，而是统称为报文。会话层不参与具体的传输，它提供包括访问验证和会话管理在内的建立和维护应用之间通信的机制。如服务器验证用户登录便是由会话层完成的。

- 建立会话：A、B两台网络设备之间要通信，要建立一条会话供他们使用，在建立会话的过程中也会有身份验证，权限鉴定等环节；
- 保持会话：通信会话建立后，通信双方开始传递数据，当数据传递完成后，OSI会话层不一定会立刻将两者这条通信会话断开，它会根据应用程序和应用层的设置对该会话进行维护，在会话维持期间两者可以随时使用这条会话传输局；
- 断开会话：当应用程序或应用层规定的超时时间到期后，OSI会话层才会释放这条会话。或者A、B重启、关机、手动执行断开连接的操作时，OSI会话层也会将A、B之间的会话断开。



#### SSL和TLS

HTTP协议采用明文传输信息，存在信息窃听、信息篡改和信息劫持的风险，而协议TLS/SSL具有**身份验证、信息加密和完整性校验**的功能，可以避免此类问题发生。

SSL协议可分为两层： **SSL记录协议**：它建立在可靠的传输协议（如TCP）之上，为高层协议提供数据封装、压缩、加密等基本功能的支持。 **SSL握手协议**：它建立在SSL记录协议之上，用于在实际的数据传输开始前，通讯双方进行身份认证、协商加密算法、交换加密密钥等。

SSL原理：

![SSL原理](https://img-blog.csdn.net/20160908134036615?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

1. 客户端将它所支持的算法列表和一个用作产生密钥的随机数发送给服务器；
2. 服务器从算法列表中选择一种加密算法，并将它和一份包含服务器公用密钥的证书发送给客户端；该证书还包含了用于认证目的的服务器标识，服务器同时还提供了一个用作产生密钥的随机数；
3. 客户端对服务器的证书进行验证，并抽取服务器的公用密钥；然后，再产生一个称作pre_master_secret的随机密码串，并使用服务器的公用密钥对其进行加密，并将加密后的信息发送给服务器
4. 客户端与服务器端根据pre_master_secret以及客户端与服务器的随机数值独立计算出加密和MAC密钥。
5. 客户端将所有握手消息的MAC值发送给服务器；
6. 服务器将所有握手消息的MAC值发送给客户端。

**`SSL协议`在握手阶段使用的是非对称加密，在传输阶段使用的是对称加密，也就是说在`SSL`上传送的数据是使用对称密钥加密的！**这并不奇怪，因为非对称加密的速度缓慢，耗费资源。其实当客户端和主机使用非对称加密方式建立连接后，客户端和主机已经决定好了在传输过程使用的对称加密算法和关键的对称加密密钥，由于这个过程本身是安全可靠的，也即对称加密密钥是不可能被窃取盗用的，因此，保证了在传输过程中对数据进行对称加密也是安全可靠的， 因为除了客户端和主机之外，不可能有第三方窃取并解密出对称加密密钥！

但是第一个环节即选择算法的环节还是有可能被篡改，中间人可能会修改这个请求，使得服务器只能选择一个较弱的加密算法，但是第5步和第6步会将双方发送的**所有**原始信息都利用协商好的密钥加密进行传输确认，如果第一步中的信息被篡改了，那么在这里是可以发现的。



#### 数字签名和数字证书

对称加密：通信双方使用的是同一个密钥对数据进行加密和解密，效率较高

非对称加密：通信双方使用的是不同的密钥进行加密，私钥只能由一方安全保管，不能外泄，而公钥则可以发给任何请求它的人。可以使用公钥或者私钥进行加密，但是只能使用私钥进行解密。

数字签名：发送方和接收方各有一套公钥和私钥，通过网络将各自的公钥发送给对方，发送方对要发送的数据使用哈希算法生成摘要，**对这个摘要使用接收方的公钥进行加密**，将加密后的密文和原始数据的明文一起发送给接收方。接收方收到数据后使用自己的私钥对数据摘要进行解密，并对收到的数据计算摘要，如果发现这两者相同那么说明数据没有被篡改，否则说明数据被修改了。

数字证书：保证双方使用的公钥是来自对方的，防止中间人使用伪造的公钥替换了真实的公钥，最终拦截了发送数据。在SSL握手过程中，服务器会使用CA的私钥非对称地加密将自己的证书并发送给客户端，客户端收到后使用CA的公钥对其进行解密和校验，由于证书加密和解密使用的是CA公开的密钥以及证书绑定了URL，并且受信任的CA都保存在操作系统中，所以数字证书不会被冒用。



#### DNS解析过程

1. 首先查找浏览器缓存，如果存在，域名解析完成，否则继续；
2. 如果浏览器自身的缓存里面没有找到对应的条目，那么会尝试读取操作系统的hosts文件看是否存在对应的映射关系,如果存在，则域名解析到此完成。
3. 如果本地hosts文件不存在映射关系，则查找本地DNS服务器(ISP服务器,或者自己手动设置的DNS服务器),如果存在,域名到此解析完成。
4. 如果本地DNS服务器还没找到的话,它就会向根服务器发出请求,进行递归查询。（根 -> 顶级 -> 权限 -> 本地）



#### CSRF、XSS、DDoS攻击

CSRF是指，当用户登陆到某个网站时，它自身可能带有这个网站的某些凭据信息（如SESSIONID等），然后攻击者获取了这个网站某个操作的请求方法，比如说删除好友需要使用POST http://www.test.com/delete 接口，那么攻击者就将这个接口请求放置在某个第三方网站中诱导用户无意中点击，这样相当于用户直接访问了接口，导致用户信息丢失。

防御CSRF的方法：带上Token请求、验证码（用户体验差）

XSS攻击是指，由于服务端过分信任用户发来的信息，不对其进行任何校验就直接使用，这可能会导致用户提交的信息中带有一部分恶意脚本或代码（可能通过URL提交、也可能通过表单方式提交）

XSS攻击解决方法：核心就是不信任用户输入消息，必须对其进行验证和消毒（例如转义、设置白名单过滤特殊字符、过滤JS事件标签点），同时对于只允许Http访问的Cookie要直接设置为HttpOnly来避免JS代码操作Cookie。



#### 布隆过滤器

本质上布隆过滤器是一种数据结构，比较巧妙的概率型数据结构，特点是高效地插入和查询，可以用来告诉你 **“某样东西一定不存在或者可能存在”**。

算法：

1. 首先需要k个hash函数，每个函数可以把key散列成为1个整数
2. 初始化时，需要一个长度为n比特的数组，每个比特位初始化为0
3. 某个key加入集合时，用k个hash函数计算出k个散列值，并把数组中对应的比特位置为1
4. 判断某个key是否在集合时，用k个hash函数计算出k个散列值，并查询数组中对应的比特位，如果所有的比特位都是1，认为在集合中。

布隆过滤器通过多个散列函数来确定某一位的值，如果这一位值被多个哈希函数赋值为1，那么就出现了不确定性，因为不确定是不是当前这个key的哈希导致这一位被设置为1，也可能是其它键设置或覆盖这一位的值。所以布隆过滤器无法精确反映一个键是否在集合中。

但是反过来，如果某一位为0，说明没有一个键的哈希将其设置为0，那表明查询的这个键一定不存在。

**布隆过滤器数据结构**

布隆过滤器是一个 bit 向量或者说 bit 数组，长这样：

![img](https://pic3.zhimg.com/80/v2-530c9d4478398718c15632b9aa025c36_1440w.jpg)

如果我们要映射一个值到布隆过滤器中，我们需要使用**多个不同的哈希函数**生成**多个哈希值，**并对每个生成的哈希值指向的 bit 位置 1，例如针对值 “baidu” 和三个不同的哈希函数分别生成了哈希值 1、4、7，则上图转变为：

![img](https://pic4.zhimg.com/80/v2-a0ee721daf43f29dd42b7d441b79d227_1440w.jpg)

Ok，我们现在再存一个值 “tencent”，如果哈希函数返回 3、4、8 的话，图继续变为：

![img](https://pic3.zhimg.com/80/v2-c0c20d8e06308aae1578c16afdea3b6a_1440w.jpg)

值得注意的是，4 这个 bit 位由于两个值的哈希函数都返回了这个 bit 位，因此它被覆盖了。现在我们如果想查询 “dianping” 这个值是否存在，哈希函数返回了 1、5、8三个值，结果我们发现 5 这个 bit 位上的值为 0，**说明没有任何一个值映射到这个 bit 位上**，因此我们可以很确定地说 “dianping” 这个值不存在。而当我们需要查询 “baidu” 这个值是否存在的话，那么哈希函数必然会返回 1、4、7，然后我们检查发现这三个 bit 位上的值均为 1，那么我们可以说 “baidu” **存在了么？答案是不可以，只能是 “baidu” 这个值可能存在。**

这是为什么呢？答案跟简单，因为随着增加的值越来越多，被置为 1 的 bit 位也会越来越多，这样某个值 “taobao” 即使没有被存储过，但是万一哈希函数返回的三个 bit 位都被其他值置位了 1 ，那么程序还是会判断 “taobao” 这个值存在。



#### 进程状态和JVM线程状态

进程包含三个状态：**运行**、**就绪**、**阻塞**

JVM定义的线程状态包括：**NEW**（创建状态）、**RUNNABLE**（运行或等待运行）、**BLOCKED**（等待锁导致的阻塞）、**WAITING**（无限等待，例如没有指定参数的Object.wait、LockSupport的park方法）、**TIME_WATING**（有限等待，例如指定时间的Object.wait、LockSupport的park以及Thread.sleep）、**TERMINATED**（中止）



#### 进程和线程的区别

1. 进程是资源分配的基本单位，线程是处理机调度的基本单位

做个简单的比喻：进程=火车，线程=车厢

- 线程在进程下行进（单纯的车厢无法运行）
- 一个进程可以包含多个线程（一辆火车可以有多个车厢）
- 不同进程间数据很难共享（一辆火车上的乘客很难换到另外一辆火车，比如站点换乘）
- 同一进程下不同线程间数据很易共享（A车厢换到B车厢很容易）
- 进程要比线程消耗更多的计算机资源（采用多列火车相比多个车厢更耗资源）
- 进程间不会相互影响，一个线程挂掉将导致整个进程挂掉（一列火车不会影响到另外一列火车，但是如果一列火车上中间的一节车厢着火了，将影响到所有车厢）
- 进程可以拓展到多机，进程最多适合多核（不同火车可以开在多个轨道上，同一火车的车厢不能在行进的不同的轨道上）
- 进程使用的内存地址可以上锁，即一个线程使用某些共享内存时，其他线程必须等它结束，才能使用这一块内存。（比如火车上的洗手间）－"互斥锁"
- 进程使用的内存地址可以限定使用量（比如火车上的餐厅，最多只允许多少人进入，如果满了需要在门口等，等有人出来了才能进去）－“信号量”



#### 进程间通信的方式

1. 管道：半双工，利用内核缓冲区进行数据传递，一个线程从一头放入数据，另一个线程从另一头取出数据，本质上类似于循环队列

   - 无名管道：因为是无名的所以只允许具有亲缘关系的进程通信
   - 命名管道：具有自己的名字，对应到磁盘上就是有对应的结点号（但是没有数据块，它是依靠内核缓冲区实现的），只要具有权限的进程都可以使用这个管道进行通信。

2. 消息队列：为了改进管道通信无法指定数据类型和次序设计的，**在系统内核中利用链表实现**，可以指定数据的优先级、规则来指定收取的数据。

3. 共享内存：共享内存允许两个或多个进程共享一个给定的存储区，这一段存储区可以被两个或两个以上的进程映射至自身的地址空间中，一个进程写入共享内存的信息，可以被其他使用这个共享内存的进程，通过一个简单的内存读取错做读出，从而实现了进程间的通信。

   它的优点就是“直接”操作内存效率高（实际上也不是直接，保护模式下对内存的操作还是要经过一系列的地址变换）。

4. 信号量

5. 信号（SIGCHLD、SIGKILL、SIGTERM等）

6. Socket



#### 线程通信方式

1. 全局变量（即进程全局变量是所有线程共享的），比如Java中volatile、sync、锁、Object:wati来实现同步访问
2. 消息队列
3. 事件机制



#### 进程上下文切换和线程上下文切换

首先，进程是由内核来管理和调度的，**进程的切换只能发生在内核态**。所以，进程的上下文不仅包括了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的状态。因此，进程的上下文切换就比系统调用时多了一步：在保存当前进程的内核状态和 CPU 寄存器之前，需要先把该进程的虚拟内存、栈等保存下来；而加载了下一进程的内核态后，还需要刷新进程的虚拟内存和用户栈。如下图所示，保存上下文和恢复上下文的过程并不是“免费”的，需要内核在 CPU 上运行才能完成。

这里比较耗时的是虚拟内存，由于操作系统内部使用TLB（快表）来加快对虚拟内存的访问，两个进程可能会出现使用了同一个逻辑地址，但是指向不同物理地址的问题，所以当进程切换时，整个TLB将会失效，这会减缓内存访问的速度。

而同一进程内线程上下文的切换就简单的多了，只要保存线程私有变量比如程序计数器、寄存器、栈信息即可；但是对于不同进程的线程切换，其耗费的时间和进程上下文切换是一致的。



#### 进程调度算法

短作业优先、先来先服务、时间片轮转、多级反馈队列



#### 页面置换算法

最优、FIFO、LRU

虚拟内存：从逻辑上扩充内存空间，对于一个程序而言，每次执行一部分，所以每次只需要将一部分程序对应的页换入物理内存中使用即可，当需要的页不在内存中时，由系统发出缺页中断，将对应的页按照页面置换算法换入内存，实现内存空间的扩展。

实现方式：请求分页、请求分段和段页式



#### 内部碎片和外部碎片

在内存管理中，**内部碎片**是已经被分配出去的的内存空间大于请求所需的内存空间。

**外部碎片**是指还没有分配出去，但是由于大小太小而无法分配给申请空间的新进程的内存空间空闲块。

固定分区存在内部碎片，可变式分区分配会存在外部碎片；

**页式虚拟存储**系统存在**内部碎片**；**段式虚拟存储**系统，存在**外部碎片**

为了有效的利用内存，使内存产生更少的碎片，要对内存分页，内存以页为单位来使用，最后一页往往装不满，于是形成了内部碎片。

为了共享要分段，在段的换入换出时形成外部碎片，比如5K的段换出后，有一个4k的段进来放到原来5k的地方，于是形成1k的外部碎片。



#### 死锁

条件：互斥、不可剥夺、持有并等待和循环等待

解决：

1. 死锁预防：
   1. 打破互斥：不实际
   2. 打破不可剥夺：等待时运行资源抢占
   3. 打破持有并等待：进程要么分配全部需要的资源，要么都不分配（资源利用率低、且资源使用难以预测）
   4. 打破循环等待：给资源标号，只有持有了小号的资源才允许获取大号的资源
2. 死锁避免：动态检测分配资源是否合理，利用资源分配图，不允许成环；银行家算法，分配一个资源时后续不许存在一个可行的、不产生死锁的分配方案
3. 死锁解除：选择一个进程牺牲、回滚到安全状态、饥饿（被回滚的越多越不能称为牺牲品，类似优先队列）

#### 

#### 软链接和硬链接

软链接就好比快捷方式，只是对文件路径的复制，这个比如创建了指向/home/aaa/a的软链接，实际上只是将/home/aaa/a复制了过来，但是/home/aaa/a它指向的实际文件的地址并没有被复制；而硬链接则是复制了实际指向的目标文件的地址。所以软链接指向的文件一旦被删除，那么软链接也随之失效，而如果在软链接指向的地址上新建一个新的文件，那么此时软链接也就指向了这个新的文件了；而硬链接指向的文件如果被删除了，那么由于硬链接也指向目标文件的实际地址，所以真正的文件并不会被删除，只是将引用计数减1，当引用计数减少到0时，才允许删除文件，否则删除的只是文件名。

Linux上实际使用inode来唯一标识一个文件，硬链接和原始文件的inode一致，所以原始文件删除并不会导致文件对应的inode被删除，文件也就不会被删除，删除的只是一个文件名；而软链接的inode和原始文件不一样，所以当原始文件被删除了（不存在其它硬链接），会导致其inode被删除，文件会真正的被删除，那么软链接指向的文件也就不存在了。

> 参考：https://blog.csdn.net/stupid56862/article/details/90785420



#### MySQL为什么使用B+树索引

Hash表：无序，不支持范围查找、排序，同时如果出现哈希冲突，那么需要的时间更长

AVL树：树高度不一定平衡，而且可能会面临倾斜问题，同时范围查找仍需要中序遍历（红黑树可以解决平衡的问题，但是无法解决范围查找的问题以及树高度过高的问题，最终导致磁盘IO次数增加，减缓速度）

B树：非叶子结点就会存储所有数据，并且一个结点只会出现一次。这样还是难以实现范围查找和排序，因为要实现范围查找还是需要中序遍历整个B树（优点是树高度降低，而每个树结点数虽然增加，但是在内存中对这些有序序列查找时的速度很快）

B+树：非叶子结点只用于索引且数值会在下一层冗余一层，最终叶子结点包含了所有数据信息，同时叶子结点之间再链接起来，构成了一个有序的链表。



#### MySQL读视图和MVCC

MySQL快照读是依赖ReadView和UndoLog实现的，每条SQL查询后面都有三个隐藏字段DB_ROW_ID（隐藏自增主键，6字节），DB_TRX_ID（当前事务ID）、DB_ROLLBACK_PTR（指向回滚段上一个数据的指针）

而读视图中也包含三个额外的表项目：TRX_LIST（当前活跃的事务ID列表）、UP_LIMIT_ID（当前活跃的最小事务ID）、LOW_LIMIT_ID（下一个事务的ID）。读视图会在首次快照读时建立，并收集以上三个项目。所以说快照读并不一定说事务ID大的事务提交后，ID小的事务就一定不可见。如果在当前这个事务首次获取快照读之前，有一个ID较大的事务COMMIT了，那么此时还是可以读到它提交的数据，其原因就在于：如果一个ID大的事务提交之后，它就不会存在于前一个事务的活动事务列表中了，同时由于这个提前结束的事务ID虽然大于当前事务ID，但是小于系统下一个要启动的事务ID，证明这个事务已经结束，数据是可以读取的。

理性思考一下也是这样，对于读取之前结束的事务，没有理由使用它的旧版本，因为在这个时间节点上，肯定没有读取过数据（没有进行过快照读，也没进行当前读（会加锁）），对于RC隔离级别来说，由于它本身就不保证可重复读，所以它永远读取最新版本的数据。



#### Buffer Pool

InnoDB数据以页的形式在磁盘和内存中存储，每个页大小为16KB，而内存中维护了一个Buffer Pool用来存储已经加载到内存中的页。InnoDB中的Buffer Pool大小为128M，Buffer Pool中有三个链表：

1. **Free链表**用来记录所有空闲的页的控制块；
2. **Flush链表**用来记录Buffer Pool里哪些页是脏页，记录了这些页的控制块（对于InnoDB而言，修改数据是当前读，会将要修改的数据先读入内存的Buffer Pool中，然后对Buffer Pool中页进行修改，这种在内存中被修改了的页即脏页，会定时刷会磁盘，同时利用redo log来保证一致性）；
3. **LRU链表**用于记录当前存在Buffer Pool中的页的控制块，按照两部分存储热数据区域和冷数据区域，当页被使用后会被重新插入到当前数据区域的头部，表明它是当前最近被使用的页，而在冷数据区域的页在经过若干次使用后也将晋升到热数据区域（冷数据区域两次访问时间间隔大于1秒会晋升），这样当需要淘汰某些页时，就可以直接从LRU链表上取下对应的页的控制块。而至于为什么要分冷数据和热数据区域是为某些全表扫描SQL会读出一些很少使用的数据将Buffer Pool中原本的数据给替换掉，而这些全表扫描的数据使用频率很低，但是却导致之前使用频繁的热数据被替换，所以将其放置在冷数据区域，只有当这些数据使用频率增加时才会放置到热数据区域。冷热数据区域比例是3：5。



Inno DB数据更新操作的顺序：

1. 更新内存Buffer Pool的页数据
2. 生成一个redo log对象
3. 事务COMMIT后根据持久化策略持久化redo log（这里内存Buffer Pool的脏页什么时候写入磁盘是不确定的）

采用这种策略的一个原因就是，**Buffer Pool中一个页对应多条数据，它们在逻辑上是连续的，但是在物理上不一定连续，所以将页写入磁盘是随机IO；但是对于redo log来说它采用的是append的方式连续写入物理页的数据，是顺序IO，它的速度要比随机IO快得多**。



#### BinLog、RedoLog和UndoLog

1. BinLog用于主从同步，是MySQL服务器层面上的日志记录，记录了每条执行的SQL语句（不包括查询），所以写入BinLog的时机是每个事务提交之后（没有事务则是每个语句执行之后）。记录方式就是对BinLog追加相应的SQL语句。

2. RedoLog用于保证数据一致性，它记录的是数据库中每个页的修改，所以在每次对数据进行修改时都要保证先写入RedoLog，再修改对应的页（如果事务中发生了回滚会记录UndoLog中反向的修改语句，覆盖RedoLog中之前的操作，所以RedoLog的内容可能会被覆盖）。RedoLog是InnoDB层面上的。

   RedoLog分为两个部分：内存中的LogBuffer、磁盘中的RedoLog文件：

   ![](https://images2018.cnblogs.com/blog/733013/201805/733013-20180508101949424-938931340.png)

   但是由于操作系统本身存在缓存的特性，并且MySQL对日志文件的读写没有启用O_DIRECT标志，导致其会使用系统缓存，所以当数据写入系统而没有刷新时，它只停留在缓存中等待操作系统将其写入文件，如果此时操作系统挂了，那数据就会丢失。所以MySQL定义了一下三个刷入策略，它们由`innodb_flush_log_at_trx_commit`变量来控制：

   - 0：将RedoLog先写入Log Buffer，然后每隔1秒写入OS Buffer并调用fsync将其写入磁盘（相当于LogBuffer间隔1秒直接写入磁盘）
   - 1：将RedoLog直接写入OS Buffer，并立即调用fsync写入磁盘（相当于RedoLog直接写入磁盘）（默认）
   - 2：将RedoLog直接写入OS Buffer，每隔1秒调用fsync写入磁盘（相当于RedoLog直接写入系统缓存，间隔1秒写入磁盘）

   这里三者的示意图如下：

   ![](https://images2018.cnblogs.com/blog/733013/201805/733013-20180508104623183-690986409.png)

可以看出，当设置为0时，会先写入LogBuffer，再刷入磁盘（这里解释一下fsync，它会将缓冲区的数据理解写入磁盘，并等待写入完毕后才会返回），它的优点就是相比默认的1快，因为不需要马上进行磁盘IO，而是由后台线程每隔1秒进行磁盘IO，缺点就是如果数据库宕机，那么数据会丢失；默认设置为1，对于所有RedoLog的修改，都会立即写入磁盘；当将其设置为2时，会立即写入缓冲区，然后每隔1秒写入磁盘，它和0的区别就是，当设置为0时，如果出现数据库宕机、进程挂、操作系统挂，那么数据会丢失，但是设置为2时，只有操作系统挂了才会导致数据丢失，而且只会丢失1秒的数据，安全性比0级高一些。

InnoDB存储引擎中，RedoLog以块为单位进行存储的，每个块占512字节，这称为Redo Log Block。所以不管是log buffer中还是os buffer中以及redo log file on disk中，都是这样以512字节的块存储的。每个Redo Log Block由3部分组成：**日志块头、日志块尾和日志主体**。其中日志块头占用12字节，日志块尾占用8字节，所以每个redo log block的日志主体部分只有512-12-8=492字节：

![](https://images2018.cnblogs.com/blog/733013/201805/733013-20180508182701906-2079813573.png)

因为redo log记录的是数据页的变化，当一个数据页产生的变化需要使用超过492字节()的redo log来记录，那么就会使用多个redo log block来记录该数据页的变化。（注意这里并不是把整个数据页都复制一份，只是记录哪个数据页的哪一块数据被改过了）

-  log_block_hdr_no：(4字节)该日志块在redo log buffer中的位置ID。
- log_block_hdr_data_len：(2字节)该log block中已记录的log大小。写满该log block时为0x200，表示512字节。
- log_block_first_rec_group：(2字节)该log block中第一个log的开始偏移位置。
-  lock_block_checkpoint_no：(4字节)写入检查点信息的位置。

其中第三个变量log_block_first_rec_group就是用来记录一个块存不下时第一个块的偏移起点。

将上面的LogBlock和RedoLog Buffer整合一下就是：

![](https://images2018.cnblogs.com/blog/733013/201805/733013-20180508182756285-1761418702.png)

RedoLog可以以组的形式保存（默认是多个），两个循环写，一个满了接着写下一个文件，如果两个都满了那么强制要求刷回一部分脏页后接着循环写。但是RedoLog组的大小和每个日志文件的大小不是越大越好，如果大小越大，那么也就意味着出错时恢复的时间也越长，如果太小，那么会导致频繁的IO（虽然是顺序IO）。

而RedoLog将数据刷回磁盘会按照以下规则：

- COMMIT操作（但是具体怎么执行依赖上面说的`innodb_flush_log_at_trx_commit`执行）
- 每秒刷一次。这个刷日志的频率由变量`innodb_flush_log_at_timeout`值决定，默认是1秒。要注意，这个刷日志频率和commit动作无关。
- LogBuffer占用超过内存的一半
- 当存在检查点时，同样检查点也有两种
  - Sharp Checkpoint：在重用redo log文件(例如切换日志文件)的时候，将所有已记录到redo log中对应的脏数据刷到磁盘
  - Fuzzy Checkpoint：一次只刷回一部分而不是整个文件
    - Master Thread Checkpoint：主线程每隔10秒刷回一次
    - Flush LRU List Checkpoint：主要是腾出LRU控制块（冷数据区域先处理，然后才是热数据）
    - Async/Sync Flush Checkpoint：当脏页数据很少时，不刷盘；当脏页数据不多时，异步；否则，同步
    - Dirty Page Too Much：当脏页太多时会进行刷盘（默认75%）

3. **UndoLog**：提供回滚和多个行版本控制(MVCC)。在数据修改的时候，不仅记录了redo，还记录了相对应的undo，如果因为某些原因导致事务失败或回滚了，可以借助该undo进行回滚。

   undo log和redo log记录物理日志不一样，它是逻辑日志。**可以认为当delete一条记录时，undo log中会记录一条对应的insert记录，反之亦然，当update一条记录时，它记录一条对应相反的update记录。**

   当执行rollback时，就可以从undo log中的逻辑记录读取到相应的内容并进行回滚。有时候应用到行版本控制的时候，也是通过undo log来实现的：当读取的某一行被其他事务锁定时，它可以从undo log中分析出该行记录以前的数据是什么，从而提供该行版本信息，让用户实现非锁定一致性读取。

   undo log是采用段(segment)的方式来记录的，每个undo操作在记录的时候占用一个undo log segment。

   另外，undo log也会产生redo log，因为undo log也要实现持久性保护。

   **InnoDB存储引擎对undo的管理采用段的方式。rollback segment称为回滚段，每个回滚段中有1024个undo log segment。**

综上，将三个日志放在一起可以得到这样一个流程图：

<img src="https://img-blog.csdnimg.cn/20190607093559118.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMzc4MDM0,size_16,color_FFFFFF,t_70" style="zoom:80%;" />



#### InnoDB双写缓冲区

InnoDB中的一页为16KB，操作系统的一页为4KB，所以将InnoDB的页写入操作系统不是一个原子操作，有可能出现只写了一部分的情况:

1. 如果写入缓冲区失败：由于原始数据已经写入RedoLog了，那么RedoLog和表空间数据叠加之后就可以得到真实数据
2. 如果缓冲区部分写入表空间：由于数据已经写入缓冲区，那么就不需要使用RedoLog，那么就可以将RedoLog对应的数据删除，然后只要将DWB和表空间数据叠加起来就是完整的数据了
3. 如果缓冲区完全写入表空间：此时可以删除缓冲区的数据，查询时只要从表空间查询即可。

示意图如下：

<img src="/images/MySQL/MySQL-DWL-Problem.png" alt="MySQL-DWL-Problem" style="zoom:50%;" />

如果缺少DWB，那么写入表空间的时候不仅原始数据会受到破坏，而且RedoLog也无法删除，会造成一系列的问题。



#### MySQL ChangeBuffer

MySQL内部数据是以页的形式读入内存的，那对于某些需要索引的操作，也需要将索引页读入内存。所以MySQL为了优化防止在修改时既需要读取数据页也需要读取索引页的问题（数据页唯一，但是索引页不一定唯一）引入了ChangeBuffer的概念，利用ChangeBuffer区来储存对应的修改语句，这样在修改数据时只IO获取数据页，同时将修改语句已经对应索引的页号、页偏移信息读取出来，一起放置在ChangeBuffer区。当需要使用索引获取数据时，此时会将索引页读到BufferPool中和ChangeBuffer整合，这样就能获取到最新的数据了。



#### MySQL自适应哈希

由于InnoDB使用B+树索引，索引每个结点实际上是一个页结构，一个页中可能存储了若干条数据，在页内查找数据时为了避免遍历整个页中的所有数据，对于高度热点的页，InnoDB会为其生成哈希索引表（即索引的索引），这个索引表只存在于内存中，占用非常小。

即Innodb存储引擎会监控对表上二级索引的查找，如果发现某二级索引被频繁访问，二级索引成为热数据，建立哈希索引可以带来速度的提升。经常访问的二级索引数据会自动被生成到hash索引里面去(最近连续被访问三次的数据)，自适应哈希索引通过缓冲池的B+树构造而来，因此建立的速度很快。结构图：

![](https://images2017.cnblogs.com/blog/1113510/201708/1113510-20170830183917780-959160821.png)

可以看出建立在B+树索引上的二级哈希索引肯定是可以加快查找速度的，但是只有在非常极端的场景下，哈希索引才能起作用，比如说非范围查找（哈希表的无序特性使其难以实现范围查找）、少更新（两级缓存需要双倍的更新时间），同时由于引入了新的索引，索引页以及数据页会占用更多的BufferPool空间。



#### InnoDB和MyISAM的区别

1. InnoDB支持事务，MyISAM不支持
2. InnoDB支持外键，MyISAM不支持
3. InnoDB是聚簇索引，使用B+树作为索引结构，叶子结点直接包含所有数据；MyISAM是非聚簇索引，也是使用B+树作为索引结构，但是其叶子结点指向的是数据文件中的地址
4. InnoDB支持表级、行级和间隙锁，MyISAM只支持表级锁
5. InnoDB对表的行数统计需要全表扫描，MyISAM由于不支持事务，所以使用了一个全局计数器来保存全表行数
6. InnoDB不支持全文索引，MyISAM支持
7. InnoDB必须有主键，没有主键的话会使用隐藏的6字节主键DB_ROW_ID，MyISAM允许没有主键
8. MyISAM表可以被压缩后进行操作，InnoDB不行



#### Redis键过期删除策略

1. 定时删除：定时扫描所有数据，删除过期的数据。（可能会浪费很多的CPU时间，比如说像List这种结构，扫描一次时间复杂度为O(n)）
2. 惰性删除：将键删除的操作延迟到取出键的时候执行。（对CPU时间最友好，但是会占用内存空间）
3. 定期删除：上面两种方案的折中，每隔一段时间执行一次清除，但是限制每次清除占用的CPU时间。

持久化时，对于RDB文件，过期的键不会被写入RDB文件中，载入RDB文件时也不会载入过期的键；对于AOF文件来说，写入命令时原样写入，键过期时会自动写入一条删除指令。

主从复制时和AOF的处理思路一致，主服务器将数据同步给从服务器，当键过期时主服务器显式地发送一条删除指令。在删除指令执行前，如果键已过期但依然收到了主服务器的读命令，那么会按照处理未过期键一样处理这条数据。



Redis内存空间满时的清除策略：

**a) 针对设置了过期时间的key做处理:**

1. volatile-ttl:在筛选时，会针对设置了过期时间的键值对，根据过期时间的先后进行删 除，越早过期的越先被删除。
2. volatile-random:就像它的名称一样，在设置了过期时间的键值对中，进行随机删除。 
3. volatile-lru:会使用 LRU 算法筛选设置了过期时间的键值对删除。

4. volatile-lfu:会使用 LFU 算法筛选设置了过期时间的键值对删除。

**b) 针对所有的key做处理:**

5. allkeys-random:从所有键值对中随机选择并删除数据。
6. allkeys-lru:使用 LRU 算法在所有数据中进行筛选删除。
7. allkeys-lfu:使用 LFU 算法在所有数据中进行筛选删除。

**c) 不处理:**

8. noeviction:不会剔除任何数据，拒绝所有写入操作并返回客户端错误信息"(error) OOM command not allowed when used memory"，此时Redis只响应读操作。



#### Redis分区和分布式一致性哈希

传统哈希方法在分布式上无法使用，主要是因为对于一个服务器而言，它计算出的哈希值对应的是当前服务器上的桶，而它并不能感知其它服务器上的桶，所以传统的哈希方法无法使用。一种简单的解决办法就是取模，将图片ID对服务器数取模，这样就能获得图片具体在哪一个服务器上的信息了。但是这种方法有很大的局限性，首先如果服务器数量增加，那么要对几乎所有的数据重新计算哈希，重新分配服务器；同理如果其中一个服务器出现故障，那么所有的图片的哈希值对服务器数的取模结果也会发生变化，导致无法获取到真实数据。

一致性哈希则将所有数据对2的32次幂取模，我们将2的32次幂看作一个圆环，将服务器的IP地址对其取模就可以将服务器映射为圆环上的一个点。当需要存取缓存信息时，只要将对应的键也对2的32次幂取模，然后**向后找到**圆环离当前这个点最近的一台服务器来存取数据即可。

<img src="https://images2015.cnblogs.com/blog/498077/201608/498077-20160822172408386-366341651.png" style="zoom:67%;" />

问题：有可能造成严重的倾斜问题，即大量的缓存信息都被存入了同一个服务器结点。

解决：引入虚拟结点，虚拟结点可以看作是物理结点的指针，指向虚拟结点的数据实际间接指向了虚拟结点对应的实际结点，这样只要合理设置虚拟结点的数量和位置，就能解决倾斜问题了。



#### 缓存击穿、穿透和雪崩

- 缓存穿透：请求了大量缓存和数据库中都不存在的数据，这样会导致每次请求都会去查找数据库
  - 解决：接口校验、缓存控制、布隆过滤器
- 缓存击穿：瞬时请求了大量缓存中不存在但数据库中存在的数据，这样导致瞬间大量请求打到数据库中
  - 解决：互斥访问、热点数据永不过期
- 缓存雪崩：同一时间有大量的缓存过期
  - 解决：热点数据永不过期、过期时间加上随机数来避免同时过期



#### 进程Fork

进程Fork就是一个进程创建了另一个进程，两个进程拥有相同的代码段、数据段、程序计数器等等，但是PID、计时器和资源使用计数器不同。就相当于父进程克隆了一份自己，新的子进程和父进程之间就是父子关系。

但是注意：子进程和父进程内存地址空间是不一致的，子进程虽然复制了父进程的所有内存数据，但只是逻辑地址相同，指向的物理地址是不同的（由于Copy On Write的存在，子进程在读取未修改过的逻辑内存地址时，实际上访问的是父进程的物理地址，只有当父进程或子进程对这块物理内存修改时，子进程才会将对应的物理内存数据拷贝到自己的内存地址空间中）

Linux中利用fork()函数（C语言, sys/types.h头文件中）创建一个子进程，父进程和子进程同时从fork的调用点开始向下执行，所以fork在父进程中会返回子进程的PID，在子进程中会返回0，通过fork的返回值就可以知道到底是父进程在执行还是子进程在执行了。

如果需要让子进程共享父进程的内存地址空间，那么可以使用vfork()方法，vfork方法创建的进程会共享父进程的内存地址空间（也就是子进程中改变了某些值，父进程中也会被改），同时vfork创建出来的子进程会阻塞父进程，保证子进程先行运行。（这个子进程就相当于线程了）



#### 内核态和用户态切换的资源消耗

当程序中有系统调用语句，程序执行到系统调用时，首先使用类似int 80H的软中断指令，保存现场，去的系统调用号，在内核态执行，然后恢复现场，每个进程都会有两个栈，一个内核态栈和一个用户态栈。当执行int中断执行时就会由用户态，栈转向内核栈。系统调用时需要进行栈的切换。而且内核代码对用户不信任，需要进行额外的检查。系统调用的返回过程有很多额外工作，比如检查是否需要调度等。 

系统调用一般都需要保存用户程序得上下文(context), 在进入内核得时候需要保存用户态得寄存器，在内核态返回用户态得时候会恢复这些寄存器得内容。这是一个开销的地方。 如果需要在不同用户程序间切换的话，那么还要更新cr3寄存器，这样会更换每个程序的虚拟内存到物理内存映射表的地址，也是一个比较高负担的操作。



#### Redis主节点的选择策略

步骤：

1. 主节点被标记为主观下线（当前哨兵结点在规定时间间隔内没有收到来自MASTER结点的心跳包）
2. 主节点被标记为客观下线（超过一定数量的哨兵集群结点确认这个MASTER结点处于主观下线状态）
3. 选举哨兵Leader，当某个哨兵结点确认主节点被标记为客观下线时，它会请求其他哨兵节点要求将自己选举为Leader。被请求的哨兵节点如果没有同意过其他哨兵节点的选举请求，则同意该请求(选举票数+1)，否则不同意。如果一个哨兵节点获得的选举票数达到Leader最低票数(`quorum`和`Sentinel节点数/2+1`的最大值)，则该Sentinel节点选举为Leader；否则重新进行选举。
4. 哨兵Leader选举新Master结点：
   1. 过滤故障节点
   2. 选择优先级大的节点作为主节点，如果没有配置则跳过
   3. 选择复制偏移量（数据写入量的字节，记录写了多少数据。主服务器会把偏移量同步给从服务器，当主从的偏移量一致，则数据是完全同步）最大的从节点作为主节点，如不存在则继续
   4. 选择`runid`（redis每次启动的时候生成随机的`runid`作为redis的标识）最小的从节点作为主节点

<img src="https://img-blog.csdnimg.cn/20201015105208279.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0xpYW9Ib25nSEI=,size_16,color_FFFFFF,t_70#pic_center" style="zoom:80%;" />



#### RabbitMQ和Kafka的区别

RabbitMQ支持典型的开箱即用的消息队列。开发者可以定义一个命名队列，然后发布者可以向这个命名队列中发送消息。最后消费者可以通过这个命名队列获取待处理的消息。RabbitMQ使用消息交换器来实现发布/订阅模式。发布者可以把消息发布到消息交换器上而不用知道这些消息都有哪些订阅者。

Apache Kafka不是消息中间件的一种实现。相反，它只是一种分布式流式系统。Kafka的存储层是使用分区事务日志来实现的。Kafka没有实现队列这种东西。相应的，Kafka按照类别存储记录集，并且把这种类别称为主题。Kafka为每个主题维护一个消息分区日志。每个分区都是由有序的不可变的记录序列组成，并且消息都是连续的被追加在尾部。当消息到达时，Kafka就会把他们追加到分区尾部。默认情况下，Kafka使用轮询分区器（partitioner）把消息一致的分配到多个分区上。

区别：

1. RabbitMQ除非是单个消费者，否则无法保证消息消费顺序；Kafka可以保证发送到每个分区中的消息被顺序消费。
2. RabbitMQ允许根据路由规则过滤消息；Kafka不允许，一个订阅的消费者在没有异常情况下会接受一个分区中的所有消息。
3. RabbitMQ支持TTL、延时消息；Kafka不支持，只能在应用中实现。
4. RabbitMQ在消息被消费后就删除消息；Kafka本质上是一个存储工具，并不关心消费是否成功，目的就是为了保存消息。
5. RabbitMQ的容错机制更简单，提供了死信交换机和交付确认机制来确保消息被正确处理；Kafka设计之出就不用于MQ，所以不支持消息确认和消息故障迁移。

使用RabbitMQ的原因：1. 符合队列思想，简单易用；2. 对消息消费顺序要求不高，但是对出错处理要求较高



#### RabbitMQ保证消息被消费

1. 生产者发送到MQ过程中丢失：

   使用事务：不推荐，会极大降低性能

   使用发布确认：单个发布确认（同步阻塞，一个消息没有被确认会影响后面的消息发送）；批量发布确认（同步阻塞，批量对信息进行确认，优点是效率比单个发布确认高，缺点是如果出错不知道是哪一个出错了，需要在内存中保存所有发送出去的消息）；异步发布确认（利用回调函数实现，实现复杂）

   回退机制：在仅开启了生产者确认机制的情况下，交换机接收到消息后，会直接给消息生产者发送确认消息，如 果发现该消息不可路由，那么消息会被直接丢弃，此时生产者是不知道消息被丢弃这个事件的。所以可以启用MQ的回退机制，当数据不可路由时回退给生产者，由生产者提供回调函数来处理这部分消息。

2. MQ中消息丢失：

   持久化：发布确认会在IO写入磁盘后MQ才进行确认，所以持久化能保证消息不丢失。

3. 消费者消费消息丢失：

   手动ACK确认



#### 保证接口幂等性

接口幂等性就是用户对于同一操作发起的一次请求或者多次请求的结果是一致的，不会因为多次点击而产生了副作用。举个最简单的例子，那就是支付，用户购买商品后支付，支付扣款成功，但是返回结果的时候网络异常，此时钱已经扣了，用户再次点击按钮，此时会进行第二次扣款，返回结果成功，用户查询余额返发现多扣钱了，流水记录也变成了两条．．．,这就没有保证接口的幂等性。

在增删改查4个操作中，尤为注意就是增加或者修改，

 A: 查询操作

查询对于结果是不会有改变的，查询一次和查询多次，在数据不变的情况下，查询结果是一样的。select是天然的幂等操作

 B: 删除操作

删除一次和多次删除都是把数据删除。(注意可能返回结果不一样，删除的数据不存在，返回0，删除的数据多条，返回结果多个,在不考虑返回结果的情况下,删除操作也是具有幂等性的)

 C: 更新操作

修改在大多场景下结果一样,但是如果是增量修改是需要保证幂等性的,如下例子:

把表中id为XXX的记录的A字段值设置为1,这种操作不管执行多少次都是幂等的
把表中id为XXX的记录的A字段值增加1,这种操作就不是幂等的

 D: 新增操作

增加在重复提交的场景下会出现幂等性问题,如以上的支付问题

常见的两种实现方案: **1. 通过代码逻辑判断实现  2. 使用token机制实现**

token保证接口幂等性的步骤：

1. **生成全局唯一的token,token放到redis或jvm内存,token会在页面跳转时获取.存放到pageScope中,支付请求提交先获取token**
2. **提交后后台校验token，执行提交逻辑,提交成功同时删除token，生成新的token更新redis ,这样当第一次提交后token更新了,页面再次提交携带的token是已删除的token后台验证会失败不让提交**



#### CMS和G1

CMS的缺点：

1. 对CPU资源敏感，默认开启（CPU核心数 + 3）/ 4 个线程用于垃圾回收，如果CPU核心数较少，那么会占用较多的CPU资源
2. 无法清除浮动垃圾，由于CMS在清除阶段是并发的，就导致在这个阶段新增的垃圾无法被清除（G1可以，G1筛选回收阶段是STW的）
3. 需要额外内存，当CMS内存不足时会使用担保机制，临时启用Serial Old作为垃圾收集器，会更长时间的停顿用户线程
4. CMS是基于标记-清除算法的（虽然可以通过虚拟机参数设置为在FullGC是自动规整内存，或进行若干次GC后规整内存，但是这两个参数已经被废弃了）

G1的优点：

1. 由于G1在初始标记、最终标记和筛选回收阶段都是STW的，它不会产生浮动垃圾
2. G1局部使用标记复制算法，整体使用标记整理算法，不会产生内存碎片，并且对于内存的分配也更简单，使用指针碰撞即可。
3. 整理速度更快，保证吞吐率，也尽量保证停顿时间

G1的缺点：

1. 为了存储跨代引用信息，需要对每个Region都保存记忆集，内存占用量大，需要利用写后屏障来实现
2. G1采用原始快照的方法记录并发标记过程中发生改变的对象图，实现复杂，需要利用写前屏障来实现
3. 并发收集时，Region内可能还会进行内存分配，这需要通过TAMS指针来标定新对象可以使用的内存区域，处理起来比较复杂



#### Redis CopyOnWrite

CopyOnWrite技术是用于解决在持久化时写入数据的冲突问题。我们知道Redis持久化时是另外fork一个进程来对数据进行持久化的（SAVE命令会阻塞当前进程，BGSAVE会fork子进程来实现持久化，默认是采用BGSAVE，这样可以保证在持久化时接收用户请求，但同样也需要更多的后置处理）。Redis fork的子进程会共享父进程的内存空间，这样才能实现父进程和子进程之间的数据共享。

但是这会带来一个问题，如果父进程更新了数据，那么此时子进程的行为就会出问题。如果使用的是SAVE指令，它是阻塞的持久化，所以不会产生问题，但是对于BGSAVE而言，它在持久化的过程中还能接收其它用户请求，而如果这些请求对数据进行了修改，那么就会带来一系列问题。所以Redis采用了COW的方式，当原始数据没有被修改的时候，持久化进程中的数据指针指向的就是原始数据的物理内存地址，而当原始数据被修改时，才会将数据复制一份到持久化进程的内存空间中（和fork是一致的）。



#### 软件开发流程

需求分析、总体设计、详细设计、软件开发、测试和系统整合、运行和维护



#### 慢查询优化

1. 开启慢查询日志，通过慢查询日志来分析到底是哪一条SQL语句出现了问题
2. 利用运行计划分析这条语句的执行情况，对于没有索引的字段要考虑是否加上索引。如果包含索引，那么要考虑type字段中使用的索引类型，如果是ALL表示全表查询，没有用到索引（有可能不符合最左前缀原则、使用OR、对索引列使用了计算或者函数、LIKE以通配符开始）。并且分析一些Extra字段，包括文件内排序、创建临时表等等都是有问题的操作（可以考虑对排序字段创建索引，对于索引应该尽可能增加而不是新建）
3. 如果以上运行计划没有问题，那就要考虑数据库的规模了，可以采用读写分离的架构来优化读写，也可以采用分库分表的方式，对数据库进行垂直分割，将不常用字段单独成表、将不常用的表单独分库；水平分割，利用一些哈希算法，将数据水平切分到不同的表中，来减少单表的访问压力。（问题：写入操作就变得复杂了，如果表在不同的数据库上就会涉及分布式事务；对于表的扩容、缩容、表数量添加等操作不友好）



#### Linux AIO

Linux的AIO有两种实现方式：glibc实现和libaio实现。

**glibc**实现是基于POSIX在用户态实现的异步IO，它利用了线程与线程之间可以异步工作的特性，使用了新的线程来完成IO请求，这种做法会额外占用CPU资源（对线程的创建、销毁、调度都存在CPU开销，并且调用者线程和异步处理线程之间还存在线程间通信的开销）。不过，IO请求提交的过程都由异步处理线程来完成了（而linux版本是调用者来完成的请求提交），调用者线程可以更快地响应其他事情。如果CPU资源很富足，这种实现倒也还不错。当调用者连续调用异步IO接口，提交多个异步IO请求时。在glibc版本的异步IO中，同一个fd的读写请求由同一个异步处理线程来完成。而异步处理线程又是同步地、一个一个地去处理这些请求。所以，对于底层的IO调度器来说，它一次只能看到一个请求。处理完这个请求，异步处理线程才会提交下一个。

实现流程：

1. 异步请求被提交到request_queue中；
2. request_queue实际上是一个表结构，"行"是fd、"列"是具体的请求。也就是说，同一个fd的请求会被组织在一起；
3. 异步请求有优先级概念，属于同一个fd的请求会按优先级排序，并且最终被按优先级顺序处理；
4. 随着异步请求的提交，一些异步处理线程被动态创建。这些线程要做的事情就是从request_queue中取出请求，然后处理之；
5. 为避免异步处理线程之间的竞争，同一个fd所对应的请求只由一个线程来处理；
6. 异步处理线程同步地处理每一个请求，处理完成后在对应的aiocb中填充结果，然后触发可能的信号通知或回调函数（回调函数是需要创建新线程来调用的）；
7. 异步处理线程在完成某个fd的所有请求后，进入闲置状态；
8. 异步处理线程在闲置状态时，如果request_queue中有新的fd加入，则重新投入工作，去处理这个新fd的请求（新fd和它上一次处理的fd可以不是同一个）；
9. 异步处理线程处于闲置状态一段时间后（没有新的请求），则会自动退出。等到再有新的请求时，再去动态创建；

缺点：基于用户态实现，底层IO调度器无法感知到，所以无法对IO操作进行一个有效优化，效率很低

**libaio**实现是基于Linux内核底层实现的异步IO，它利用了CPU和IO设备可以异步工作的特性（IO请求提交的过程主要还是在调用者线程上同步完成的，请求提交后由于CPU与IO设备可以并行工作，所以调用流程可以返回，调用者可以继续做其他事情）。相比同步IO，并不会占用额外的CPU资源。同时底层的IO调度器可以看到所有的IO请求，请求多了，IO调度器使用的类电梯算法就能发挥更大的功效。请求少了，极端情况下（比如系统中的IO请求都集中在同一个fd上，并且不使用预读），IO调度器总是只能看到一个请求，那么电梯算法将退化成先来先服务算法，可能会极大的增加碰头移动的开销。同时libaio是不支持非Direct IO（即使用缓存的IO），只支持Direct IO（即应用程序buffer直接和IO设备交互，不通过系统缓存），因为非直接IO写入内存的效率本来也不差，用了AIO之后反而可能导致效率下降。

实现流程：

<img src="https://oscimg.oschina.net/oscnet/d509edee96e2fa65c44bbd7b962ddb68819.png" style="zoom:80%;" />

可以看到对于libaio，只在用户进程中提交IO请求，然后就由内核负责将IO请求提交到IO调度器，由IO调度器调度IO设备异步地读写数据，对于读取操作，会直接写入预先在用户空间分配的内存地址中。



#### Linux IO接口总结

read / write：传统同步IO方法，不支持指定偏移量，只能从上一次读写结束的偏移量处开始读写。在多线程连续读写时会有并发问题（会修改文件当前的偏移量）。

pread / pwrite：传统同步IO方法，支持指定偏移量，线程安全，函数本身不会改变文件当前的偏移量，只是在指定的偏移量处开始读写。

readv / writev：传统同步IO方法，支持对不连续的数据进行读写操作，通过传入一个类似链表的结构可以实现非连续的存储。

preadv / pwritev：上面两个的结合

多种IO方式总览：

![](https://pic1.zhimg.com/80/v2-b72e4bd5b4a943759433faf929d43c98_1440w.jpg)



#### Linux IO-Uring

IO-Uring相比libaio的若干改进点如下：

1. 解决了libaio中需要多次系统调用的缺点（io_submit/io_getevents开销大），IO-Uring通过将有限次系统调用改进为常数次系统调用来提升系统性能（有点类似epoll相对于select的改进）

2. 解决拷贝开销大的问题。通过让内核和用户进程共享一块用户进程空间的内存空间来实现零拷贝，并且搭配上生产者-消费者模式来实现高效的读写，对于共享内存而言无需加锁，只要通过环形缓冲区读、写指针的相对位置就可以实现同步。（实际上包括SQ和CQ两个队列，SQ队列是用户写入内存，CQ队列是内核写入内存）

   <img src="https://pic3.zhimg.com/80/v2-8c970e163d9894ff59bfce4a83f2a7fe_1440w.jpg" style="zoom:67%;" />

注意SQ和CQ实现的是环形队列，IO_URING支持轮询模式（Polling）。轮询是指CPU不断询问每一个IO设备是否需要提供服务，会浪费CPU时间，但是对于高速存储设备而言，其性能要比中断好得多。



#### 服务降级、服务熔断、服务限流

Loadbalanced + OpenFeign: Loadbalanced基于代理实现，利用了RestTemplate的拦截器实现的，在请求发出前会调用对应的拦截器，由拦截器将微服务名根据轮询算法映射为对应的IP和端口号，接着由RestTemplate发出请求。OpenFeign集成了LoadBalancer，在启动时，通过SPI注入配置类，该配置类实现了ImportBeanDefinitionRegister接口，可以注册Bean，它会扫描被FeignClient注解的接口生成对应的FactoryBean加入到IoC容器中，FactoryBean取出时会取出一个JDK动态代理对象，由这个代理对象负责负载均衡和请求工作。

Hystrix：



#### Linux物理内存结构

对于32位系统，每个应用程序可以使用的虚拟内存空间都是4G（无论是否有这么大的物理内存，虚拟内存到物理内存的映射由操作系统完成，如果内存不够了，那么会由操作系统抛出异常），对于32位系统，其虚拟内存的0\~3G的内存地址空间均为用户地址空间，3G\~4G的内存地址空间为内核地址空间，如下图：

<img src="/images/Linux/Linux 32位虚拟内存地址结构.png" alt="Linux 32位虚拟内存地址结构" style="zoom:50%;" />

虚拟内存中，用户地址空间是各个进程独享的，两个进程使用同样的虚拟内存地址互不影响。内核地址空间是各个进程共享的，两个进程不能使用同样的虚拟内存地址，例如每个进程都存在内核栈，内核栈存储在内核地址空间中，对于进程1假设它占用了0x4000 - 0x6000的内存的地址空间，那么进程2的内核栈就不能占用同一个内存地址了，它的内核栈就要从0x6000开始向上生长。

用户地址空间可以分为以下几个部分：

<img src="/images/Linux/Linux 用户地址空间.png" alt="Linux 用户地址空间" style="zoom:50%;" />

可以看到，对于用户地址空间而言，它包含了代码段、数据段、BSS段（未初始化的数据）以及堆、栈和内存映射信息（用于将磁盘文件直接映射到内存中，是一种高效IO方式，例如libc.so等动态库都是直接加入mmap段）

从操作系统原理中可以知道，程序装入内存是以页为单位进行装入的，对于用户地址空间而言，一般采用段页式管理，对于32位Linux系统，页和页框的大小均为4KB，对于64位系统可以支持8KB的页。（页是将程序划分之后使用的一种单位，每一页都会装入到内存的某个页框中，页框是内存中的固定位置的描述，页需要寻找一个页框装入）。Linux对于页这个结构做了多层的抽象，可以将物理内存分为页、区和节点三级结构。其中区就是对页的一个逻辑抽象（有一点像分段管理一样，将程序分为若干个逻辑段，区也是同理）。

Linux物理内存分区的结构如下：

<img src="/images/Linux/Linux物理内存结构.png" alt="Linux物理内存结构" style="zoom:50%;" />

对于32位系统且拥有4G物理内存的情况下，一般将低16MB作为DMA区，供DMA设备直接访问；16MB\~896MB作为NORMAL区，建立从逻辑内存到物理内存的线性映射（也就是内核通过加上一个偏移量就可以直接访问到这个内存区域）；而大于896MB的区域均为高端内存区域，如果要使用这些内存区域，那么必须建立临时映射来访问。当然NORMAL和DMA空间的约束并不是固定的，只是一种约束而已，当NORMAL区耗尽时是可以占用DMA区的。

之所以采用这种分区是因为，内核既需要访问内核地址空间，还需要访问用户地址空间，而我们知道内核的虚拟内存地址空间只有1G，那么要使用这1G的地址来访问全部4G的数据就需要进行一些间接处理，Linux采用的处理方式是，对于内核需要经常使用的数据（例如内核栈，内核栈实际保存了由用户态切换到内核态时用户态中的各种关键信息，例如用户栈地址、寄存器信息等），将他们存储在NORMAL区，只需要通过线性映射就可以访问到，而其它数据则在内核的高128M空间建立一个临时映射来访问，当访问结束后要释放这个临时映射来释放内核空间。（注意上面的图是物理内存结构，内核在虚拟内存中占用3G\~4G的地址空间，而在物理内存中则占用0\~1G的物理内存空间）。当然也可以创建永久映射来实现内核空间到用户空间的永久内存映射关系。

对于64位系统而言，由于其可以表示的内存地址空间非常大，目前实际只会使用48位（即支持最高256GB的内存），在这种情况下，内核地址空间完全可以表示所有的内存空间，所以对于64位系统而言，它只有NORMAL区和DMA区，没有HIGHMEM区，所有内存都是从虚拟内存到物理内存的线性映射。



#### 伙伴系统和Slab

**伙伴系统**从物理连续的大小固定的段上进行分配。从这个段上分配内存，采用 2 的幂分配器来满足请求分配单元的大小为 2 的幂（4KB、 8KB、16KB 等）。请求单元的大小如不适当，就圆整到下一个更大的 2 的幂。例如，如果请求大小为 11KB，则按 16KB 的段来请求。

让我们考虑一个简单例子。假设内存段的大小最初为 256KB，内核请求 21KB 的内存。最初，这个段分为两个伙伴，称为 AL 和 AR，每个的大小都为 128KB；这两个伙伴之一进一步分成两个 64KB 的伙伴，即 BL 和 BR。然而，从 21KB 开始的下一个大的 2 的幂是 32KB，因此 BL 或 BR 再次划分为两个 32KB 的伙伴 CL 和 CR。因此，其中一个 32KB 的段可用于满足 21KB 请求。这种方案如图 1 所示，其中 CL 段是分配给 21KB 请求的：

![](http://c.biancheng.net/uploads/allimg/181109/2-1Q10910291c62.gif)

伙伴系统的一个优点是：通过称为合并的技术，可以将相邻伙伴快速组合以形成更大分段。例如，在图中，当内核释放已被分配的 CL 时，系统可以将 CL 和 CR 合并成 64KB 的段。段 BL 继而可以与伙伴 BR 合并，以形成 128KB 段。最终，可以得到原来的 256KB 段。

伙伴系统的明显缺点是：由于圆整到下一个 2 的幂，很可能造成分配段内的碎片。例如，33KB 的内存请求只能使用 64KB 段来满足。事实上，我们不能保证因内部碎片而浪费的单元一定少于 50%。

伙伴系统出现的目的是为了消除外部碎片，由于伙伴系统将连续的内存划分为若干级别等大的块一次性进行分配，块与块之间不存在任何碎片空间，所以规避了外部碎片，但是伙伴系统会导致产生内部碎片，浪费的空间<50%。



分配内核内存的第二种策略称为**slab分配**。每个 slab 由一个或多个物理连续的页面组成，每个 cache 由一个或多个 slab 组成，每个内核数据结构都有一个 cache。

例如，用于表示进程描述符、文件对象、信号量等的数据结构都有各自单独的 cache。每个 cache 含有内核数据结构的对象实例（称为 object）。例如，信号量 cache 有信号量对象，进程描述符 cache 有进程描述符对象，等等。

![](http://c.biancheng.net/uploads/allimg/181109/2-1Q10910294Y03.gif)

图 2 显示了 slab、cache 及 object 三者之间的关系。该图显示了 2 个大小为 3KB 的内核对象和 3 个大小为 7KB 的对象，它们位于各自的 cache 中。

slab 分配算法采用 cache 来存储内核对象。在创建 cache 时，若干起初标记为 free 的对象被分配到 cache。cache 内的对象数量取决于相关 slab 的大小。例如，12KB slab（由 3 个连续的 4KB 页面组成）可以存储 6 个 2KB 对象。最初，cache 内的所有对象都标记为空闲。当需要内核数据结构的新对象时，分配器可以从 cache 上分配任何空闲对象以便满足请求。从 cache 上分配的对象标记为 used（使用）。

让我们考虑一个场景，这里内核为表示进程描述符的对象从 slab 分配器请求内存。在 Linux 系统中，进程描述符属于 struct task_struct 类型，它需要大约 1.7KB 的内存。当 Linux 内核创建一个新任务时，它从 cache 中请求 struct task_struct 对象的必要内存。cache 利用已经在 slab 中分配的并且标记为 free (空闲）的 struct task_struct 对象来满足请求。

在 Linux 中，slab 可以处于三种可能状态之一：

1. 满的：slab 的所有对象标记为使用。
2. 空的：slab 上的所有对象标记为空闲。
3. 部分：slab 上的对象有的标记为使用，有的标记为空闲。


slab 分配器首先尝试在部分为空的 slab 中用空闲对象来满足请求。如果不存在，则从空的 slab 中分配空闲对象。如果没有空的 slab 可用，则从连续物理页面分配新的 slab，并将其分配给 cache；从这个 slab 上，再分配对象内存。

slab 分配器提供两个主要优点：

1. 没有因碎片而引起内存浪费。碎片不是问题，因为每个内核数据结构都有关联的 cache，每个 cache 都由一个或多个 slab 组成，而 slab 按所表示对象的大小来分块。因此，当内核请求对象内存时，slab 分配器可以返回刚好表示对象的所需内存。
2. 可以快速满足内存请求。因此，当对象频繁地被分配和释放时，如来自内核请求的情况，slab 分配方案在管理内存时特别有效。分配和释放内存的动作可能是一个耗时过程。然而，由于对象已预先创建，因此可以从 cache 中快速分配。再者，当内核用完对象并释放它时，它被标记为空闲并返回到 cache，从而立即可用于后续的内核请求。

总结一下就是，slab分配器会缓存一部分从伙伴系统中获取的连续物理页，然后由slab分配器负责对一个或若干页的数据进行进一步的细分，比如一个程序从伙伴系统中获取了64KB的连续物理页，但是只需要使用其中的33KB，那么slab分配器就分配等大的物理空间给这个程序，剩下的31KB可以留给下一个程序使用，从而达到对伙伴系统分配的大内存进行细分的目的。

#### Linux进程和线程



#### Linux内核栈、用户栈、线程栈



#### BeanDefinition

**GenericBeanDefinition** : 通用的bean实现，自2.5以后新加入的bean文件配置属性定义类，是ChildBeanDefinition和RootBeanDefinition更好的替代者。

**AnnotatedGenericBeanDefinition**：存储@Configuration注解注释的类

**ScannedGenericBeanDefinition**：存储@Component、@Service、@Controller等注解注释的类

spring初始化时，会用GenericBeanDefinition或是ConfigurationClassBeanDefinition（用@Bean注解注释的类）存储用户自定义的Bean，在初始化Bean时，又会将其转换为RootBeanDefinition。（编程定义是一般使用GenericBeanDefinition）

GenericBeanDefinition的patentName属性指定了当前类的父类，最重要的是它实现了parentName属性的setter、getter函数，RootBeanDefinition没有parentName属性，对应的getter函数只是返回null，setter函数不提供赋值操作，所以说GenericBeanDefinition一个类就可以实现RootBeanDefinition和ChildBeanDefinition的功能，所以定义时使用GenericBeanDefinition更简洁）

也就是说RootBeanDefinition不提供继承相关的操作，但是初始化时使用的是RootBeanDefinition，那父类的性质如何体现？

这里要注意一点，子类会覆盖父类中相同的属性，所以Spring会首先初始化父类的RootBeanDefinition，然后根据子类的GenericBeanDefinition覆盖父类中相应的属性，最终获得子类的RootBeanDefinition，这个比较巧妙，不需要使用两个对象来体现父类与子类的关系，**这样就最终得出Spring中的mergedBeanDefinition了，就是父类定义和子类定义合并之后的结果。**



这里对于Bean而言，父Bean的作用更多的是用于共享配置，如果若干个Bean有统一的定义配置，那么可以设置一个公共的parent，这样在初始化子类时，会用子类的配置覆盖父类的配置，但是子类没有提供的配置会沿用父类的配置。这种情况下可以设置父类Bean的abstract属性为true，这样就不会导致其被初始化，而只是起一个模板的作用。但是要注意，子类和父类必须要保持兼容，也就是在父类Bean中提供的属性在子类中也必须存在，否则会报错。

例如下面这段代码：如果父类Bean定义了class属性，那么子类Bean就必须和它一致，此时父类bean起的就是同一个类中的模板作用：

```xml
<beans>
...
<bean id="testProxy" class="org.springframework.transaction.interceptor.TransactionProxyFactoryBean"
        abstract="true">
        <property name="transactionManager" >
            <ref bean="transactionManager"/>
        </property>
        <property name="proxyTargetClass" value="true" />

        <property name="transactionAttributes">
            <props>
                <prop key="*insert*">PROPAGATION_REQUIRED</prop>
                <prop key="*select*">PROPAGATION_REQUIRED,readOnly</prop>
            </props>
        </property>
    </bean>

    <bean id="test" parent="testProxy">
        <property name="target">
            <ref bean="testit"/>  //******(2)
        </property>
    </bean>
</beans>
```

但是如果父类Bean中没有提供class，那么此时的父类Bean就纯粹只是一个模板：

```xml
<beans>
<bean id="parentBean">
    <property name="name"><value>parent</value></property>
    <property name="age"><value>1</value></property>
</bean>
<bean id="sunBean" class="SunBean"
      parent="parentBean" init-method="initialize">
    <property name="name"><value>override</value></property>
</bean>
```

无论是是上面的哪一种情况，子类中都必须包含父类中已有的属性，否则都会报错。



#### Spring 三级缓存

三级缓存主要用于解决循环依赖问题，其中最高一级为SingletonObjects，主要用于存储已经完成全部初始化可供正常使用的Bean；第2级为EarlySingletonObjects，这一层用于存储已经被提前暴露使用，并且执行完提前暴露后置处理的所有Bean；第3级为SingletonFactories，这一层用于存储可供提前暴露但还没有执行提前暴露后置处理的所有Bean。

当一个Bean加载到属性装配之前时，如果满足：1. 单例Bean；2. 设置允许循环依赖；3. 当前Bean还处在加载过程中时，那么会将当前Bean封装为一个ObjectFactory加入到SingletonFactories集合中；当属性装配过程中如果有其它Bean依赖当前Bean，那么会直接从SingletonFactories中取出对应的Bean，并执行后置处理，然后将当前Bean移出SingletonFactories移入EarlySingletonObjects中。

这里的后置处理为：

```java
protected Object getEarlyBeanReference(String beanName, RootBeanDefinition mbd, Object bean) {
	Object exposedObject = bean;
	if (!mbd.isSynthetic() && hasInstantiationAwareBeanPostProcessors()) {
		for (SmartInstantiationAwareBeanPostProcessor bp : 
                getBeanPostProcessorCache().smartInstantiationAware) {
			exposedObject = bp.getEarlyBeanReference(exposedObject, beanName);
		}
	}
	return exposedObject;
}
```

显然这里的后置处理器为所有`SmartInstantiationAwareBeanPostProcessor`的实现类，这个接口的主要作用就是预测已处理Bean的最终类型的回调，它的父接口`InstantiationAwareBeanPostProcessor`主要用于添加实例化前回调，以及实例化后但在设置显式属性或自动装配之前的回调。通常用于抑制特定目标 bean 的默认实例化，例如创建具有特殊 TargetSource 的代理（池化目标、延迟初始化目标等），或实现额外的注入策略，例如字段注入。

**但是，如果支持循环引用，那么无论是否真的发生循环引用，上面的后置处理器都会执行。**



#### 设计消息队列

围绕三个组件来完成：1. 消息生产者；2. 中间的代理对象；3. 消息消费者

生产者和消费者这边主要要关注的就是生产者生产的消息怎么样投递到代理对象中，消费者请求的数据怎么分发到消费者中。首先要关注通信协议，可以考虑使用通用的RPC协议来完成远程过程调用以发送消息，而中间的代理对象还要负责高效地处理所有的请求，无论是生产还是消费，这里可以考虑将连接器抽象出来，实现一个IO多路复用模式或者其它的Reactor模式来负责网络连接和IO操作。

代理对象还要保证自身在内存中的存储结构，可以实现一个类似链表的结构来对队列数据进行组织，当然基于内存的存储只适合数据量不大且一致性要求不高的场景，因为内存无法存储大量数据且无法持久化存储，所以使用内存存储要谨慎。

如果基于磁盘存储，那么要考虑磁盘的存储格式，或者直接使用DB来存储，这样存储量就会上升，可靠性也会增强，但是效率就会下降（如果要自己设计，可以考虑采用MySQL那种BufferPool的结构，在内存中建立缓存，并且使用类似Redis的架构，单线程读取，多线程持久化，缺点：单线程读取磁盘文件会导致其它请求被阻塞，更倾向于每个队列一个线程）。还要考虑持久化策略，这里可以参考Redis的持久化策略（BGSAVE、COW、RDB、AOF）

同时复杂的MQ还要支持消息的可靠投递、支持消息类型、支持单播、多播、主题、订阅发布等多种模式等功能。



#### 分布式事务

1. 2阶段提交（2PC）

    引入协调者，由协调者向各个节点上的数据库发送指令，并由协调者确认每个数据库事务是否都执行成功，如果都成功了，那么协调者发出指令让每个数据库提交事务，反之如果有一个失败了，那么协调者发出指令让所有数据库回滚事务：

    **运行过程**

    1.1 准备阶段

    协调者询问参与者事务是否执行成功，参与者发回事务执行结果。

    ![img](https://oscimg.oschina.net/oscnet/62cf113cd8c40eaafecb9fc6111beef4480.jpg)

    1.2 提交阶段

    如果事务在每个参与者上都执行成功，事务协调者发送通知让参与者提交事务；否则，协调者发送通知让参与者回滚事务。

    需要注意的是，在准备阶段，参与者执行了事务，但是还未提交。只有在提交阶段接收到协调者发来的通知后，才进行提交或者回滚。

    ![img](https://oscimg.oschina.net/oscnet/6610fc7d97c9277423a9c620487e09db3f8.jpg)

    **存在的问题**

    2.1 同步阻塞 所有事务参与者在等待其它参与者响应的时候都处于同步阻塞状态，无法进行其它操作。

    2.2 单点问题 协调者在 2PC 中起到非常大的作用，发生故障将会造成很大影响。特别是在阶段二发生故障，所有参与者会一直等待状态，无法完成其它操作。

    2.3 数据不一致 在阶段二，如果协调者只发送了部分 Commit 消息，此时网络发生异常，那么只有部分参与者接收到 Commit 消息，也就是说只有部分参与者提交了事务，使得系统数据不一致。

    2.4 太过保守 任意一个节点失败就会导致整个事务失败，没有完善的容错机制。



#### Spring事务失效的几种情况

1. @Transactional注解了非public方法
2. 内部方法调用（事务基于AOP实现，代理拦截过程在AOP的ReflectiveMethodHandler中，直接调用方法不会触发拦截）（可以采用注入自己或AopContext+exposeProxy来实现）
3. 方法内部利用try catch捕获异常导致Spring没有检测到发生异常，事务会失效
4. 未配置事务管理器，或数据库不支持事务，如MyISMA



#### HashMap树化阈值为8的解释

首先HashMap树化要满足多个条件：当某个桶的长度超过阈值8时，首先检查当前桶数组的长度是否大于阈值64，如果没有大于64，那么首先会尝试将桶数组的长度加倍。如果桶数组长度已经达到阈值64了，那么才会尝试树化。

而这个桶长度阈值8是根据概率分布计算出来的，对于一个散列性能较好的hash函数，其满足泊松分布，达到桶长度8的概率几乎可以忽略不计，所以对于设计好的hash函数，它几乎不会使用到红黑树来存储，（红黑树要花费普通节点2倍的存储空间来存储）。

但是为了应对自己设计的hash函数散列不均匀的问题，所以引入了红黑树来减少在拉链法遍历链表带来的时间开销。





#### Java高并发解决方案

扩容：水平扩容、垂直扩容

缓存：Redis、Memcache、GuavaCache等、构建多级缓存

队列：Kafka、RabitMQ、RocketMQ等

应用拆分：服务化Dubbo与微服务Spring Cloud

限流：Guava RateLimiter使用、常用限流算法、自己实现分布式限流等

服务降级与服务熔断：服务降级的多重选择、Hystrix

数据库切库，分库分表：切库、分表、多数据源

高可用的一些手段：任务调度分布式elastic-job、主备curator的实现、监控报警机制9



#### 零拷贝技术

考虑一个现实场景，如果我们要将数据从文件中读取出来



#### 程序编译到运行的过程

A. 编译

1. 词法分析

2. 语法分析
3. 语义分析
4. 优化器优化
5. 目标代码生成

B. 链接

1. 静态链接：在程序运行之前就把各个模块和一些所需要的库函数链接成一个完整的可执行程序，之后就不在拆开。
2. 装入时动态链接：将应用程序装入内存时采用动态链接的方法，将程序需要的运行库一次性映射到进程的内存地址空间中。
3. 运行时动态链接：对于某些目标块的链接，是在程序执行的过程需要哪个目标模块，再把对应的目标模块装入内存，也就链接到调用者模块上。这种装入策略便于修改和更新，有利于实现我对模块的共享。

C. 装入

1. 绝对装入：在编程的时候就知道程序将要驻留在内存的物理地址，编译时程序产生含有物理地址的目标代码，这种方式只适合单道程序设计。

2. 可重定位装入（静态重定位）

    根据内存当前的情况，将装入模块装入到内存的适当位置，地址变换要一次性完成，UI后就不能再改变。

    作业装入内存时必须分配其所需要的全部内存空间，如果没有足够的空间就不能装入该作业，并且它一装入内存之后就不能再移动。

    **总而言之就是在装入时完成虚拟地址到物理地址的映射，之后不能改变这种映射关系。**

3. 动态运行时装入：

    允许程序运行时在内存中移动位置，把装入模块装到内存后的地址都是相对地址，在程序执行的时候每当要访问相应的指令或者数据的时候，才将要访问的指令或者数据的相对地址转化成物理地址。这个转化的过程要借助重定位寄存器，重定位寄存器存放的是装入模块在内存中的起始地址，  最终物理地址=重定位寄存器中的地址（装入模块在内存的起始）+逻辑地址。



#### HTTP区别

1. HTTP1.0和1.1的区别

    a. 优化缓存，Header提供了更多的缓存字段

    b. 优化部分传输，206状态码允许只传输一部分的数据

    c. 支持长连接

2. HTTP1.1和2.0的区别

    a. 基于二进制传输，Http1.x基于文本传输（文本表现形式较多，需要额外解析）

    b. 支持多路复用，赋予request一个id，使每个request可以混合在一起

    c. header压缩，双方缓存一个header表，并对header进行压缩传输，每次只传输header中变化的部分即可

    d. 服务端推送，提前请求资源



所谓多路复用，HTTP1.1也支持，但是只是支持串行的复用，即所有request可以共用一个HTTP连接，但是发送时必须按顺序发送；HTTP2赋予request id之后，request的发送就可以随机地和其它requst混合在一起进行发送了：

<img src="http://mmbiz.qpic.cn/mmbiz_png/cmOLumrNib1cfBOtIMQ6JfSibJdd6QkQriba5ygCTOOjIQH4wvoJS2iaFBseyEAUfvpJQThHmTjuGuaSspUo8xppiaA/0?wx_fmt=png" style="zoom:80%;" />

#### HTTP缓存方式

1. 强制缓存

    直接使用在浏览器内部的缓存数据，不再请求服务器（HTTP状态码为200），依靠第一次请求资源时附带的过期时间如 Expire或Cache max-age来区分。

    优点：速度快

    缺点：如果缓存在有效期内服务器数据发生了改变，那么浏览器无法获取到这种变化

2. 对比缓存

    在首次请求数据时，同时获取数据Etag，然后每次请求时附带这个Etag，由服务器判断浏览器中的Etag和服务器中的Etag是否一致，如果一致则直接返回304；否则返回最新的数据以及对应的Etag

流程图：

![](https://img-blog.csdnimg.cn/20200622174450337.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNjQ4NjMx,size_16,color_FFFFFF,t_70)



#### MySQL 双路排序和单路排序

双路排序：指在排序时只需要将排序字段和对应的记录id（即\<sort_key, rowid\>）取出来放到sort buffer中进行排序即可，好处是更节省空间，在有限的内存空间可以排序更多的字段；缺点是由于内存中只存储了对应记录的rowid，所以排序结束后还需要重新读取这些数据并且进行重新组织（回表）。

单路排序：为了解决双路排序后需要重新组织数据而产生的，它的做法是在排序时将所有字段的数据都读取到sort buffer中（即\<sort_key, additional_fields \>），这样做的好处是排序后不需要重新IO来获取数据，缺点是sort buffer中可排序的字段总数变少了，此时如果说sort buffer容纳不下所有需要排序的字段，那么就会导致产生临时文件，通过文件归并排序的方式来完成整个排序过程，这样单路排序的IO次数就会上升，这就是单路排序失效。

可以通过修改`max_length_for_sort_data`来控制当每行数据大于某个阈值时使用双路排序（默认是1KB），也可以修改`sort_buffer_size`来扩大sort buffer的空间（默认是1MB）。

一般来说双路排序和单路排序都有可能出现失效的情况，即退化为文件的归并排序。所以一般的优化思路有：

1. 尽可能减少排序后查询的字段数量，降低单路排序内存占用
2. 提高sort buffer的大小
3. 尽可能使用索引排序，例如覆盖索引的情况



#### MySQL索引设计思路

核心思路：利用一两个复杂的联合索引覆盖大部分业务，抗下尽可能多的请求，然后再辅助一两个辅助索引抗下一些其它的非典型查询，保证大数据量表的查询尽可能多的利用索引。

在设计索引的时候一般优先满足where，再满足order by。因为where的作用是过滤数据减少数据，在少数据的场景下使用order by的成本会显著降低；而order by的作用只是排序，等于是先对未完全过滤的数据排序，然后再进行过滤，这样对于部分排序操作就是无意义的，所以一般来说先尽可能的过滤掉数据，再考虑排序的问题。



#### MySQL索引优化思路

1. LIMIT优化

    如果主键自增连续，那么可以采用where，比如id连续有序，那么取90000到90005条记录可以这样写：

    ```sql
    SELECT * FROM table WHERE id >= 90000 LIMIT 5;
    ```

    否则，一般使用覆盖索引，如果以主键排序可以这样：

    ```sql
    SELECT * FROM table ORDER BY id LIMIT 90000, 5;
    ```

    如果是一般字段排序，那么按以下这个覆盖索引思路：

    ```sql
    SELECT * FROM table t1 INNER JOIN (SELECT t2.id FROM table t2 ORDER BY name LIMIT 90000,5) t3 ON t1.id = t3.id;
    ```

2. JOIN优化

    MySQL内部采用两种JOIN算法：NLJ算法和BNL算法

    a. NLJ算法

    一次一行循环地从第一张表（称为驱动表）中读取行，在这行数据中取到关联字段，根据关联字段在另一张表（被驱动表）里取出满足条件的行，然后取出两张表的结果合集。

    很显然，这种算法只有在建立索引的时候效率比较高，因为当t1表和t2表关联时（INNER JOIN），以数据量小的表作为驱动表，数据量大的表为被驱动表。这里假设t1有10000条数据，为被驱动表；t2有100条数据，为驱动表。那么NLJ算法的执行逻辑是，从t2中循环取出每一条数据，然后查询t1，如果有匹配那么就加入结果集，否则丢弃。

    可以看出如果t1和t2表对于关联字段建立了索引，那么只需要扫描t1表的索引树100次即可得到结果，如果是唯一索引，那么总共只需要扫描100次即可；如果是非唯一索引，那么可能扫描多于100次，但是不需要全表扫描，效率较高。

    如果反过来，没有建立索引树的情况，那么两表就都需要全表扫描了，扫描次数为100*10000次，此时不适合使用NLJ算法，改使用BNL算法。

    **判断是否使用了NLJ算法的依据就是在EXPLAIN执行计划中不存在Using Join Buffer**

    b. BNL算法

    为了避免NLJ算法在无索引时会扫描全部磁盘数据，BNL算法将被驱动表数据读入内存中的join buffer中，在join buffer中进行比较。以上述例子，扫描次数为100 + 10000 = 10100次，内存比较次数为100 * 10000次。

    join_buffer的大小是由参数join_buffer_size设定的，默认值是256k。如果放不下表t2的所有数据话，策略很简单，就是分段放。比如t2表有1000行记录，join_buffer一次只能放800行数据，那么执行过程就是先往join_buffer里放800行记录，然后从t1表里取数据跟join_buffer中数据对比得到部分结果，然后清空join_buffer，再放入t2表剩余200行记录，再次从t1表里取数据跟join_buffer中数据对比。所以就多扫了一次t1表。

    

    JOIN核心优化思路：**关联字段加索引、小表驱动大表（参与join的数据量较小的表为小表）**

    

3. IN和EXISTS优化

    原则：小表驱动大表

    a. IN

    ```sql
    SELECT * FROM A WHERE id IN (SELECT id FROM B)
    ```

    当B表数据量小于A表时，以上语句IN优于EXISTS。因为在执行顺序上，IN内的条件子查询会先执行；而EXISTS后的条件会后执行。

    也就是说它等价于：

    ```sql
    for (select id from B):
    	select * from A where A.id = B.id
    ```

    b. EXISTS

    ```SQL
    SELECT * FROM A WHERE EXISTS (SELECT 1 FROM B WHERE A.id = B.id)
    ```

    而上面这条语句会先执行外面的，即：

    ```sql
    for (select * from A):
    	select * from B where a.id = b.id;
    ```

    很明显，如果外部A表的数据少于B，那么采用EXISTS更优。

    总而言之：**如果外表更小，优先使用EXISTS；如果内表更小，优先使用IN。**

    （EXISTS可以使用JOIN替代）

4. COUNT(*)优化

    COUNT(1)、COUNT(id)、COUNT(*)执行效率差不多，使用的索引都不好说，尤其是主键的count，MySQL会计算扫描聚簇索引树的cost和辅助索引树的cost，选择较少的那个（实测一般不用聚簇索引树，可能考虑聚簇索引树要读取全部的数据页）。

    一般来说：

    字段有索引：count(*)≈count(1)>count(字段)>count(主键id)。字段有索引，count(字段)统计走二级索引，二级索引存储数据比主键索引少，所以count(字段)>count(主键id)，但是如果COUNT(主键)也走二级索引了，那就一样了。

    字段无索引：count(*)≈count(1)>count(主键id)>count(字段)。很显然，字段无索引，它一定全表扫描，速度肯定最慢。

    

    注意：如果表很大时，不管哪种COUNT(*)都很慢（MyISAM不支持事务，所以MyISAM会维护一个字段统计行数；InnoDB支持事务以及MVCC导致难以统计数据，所以没有维护这个值）

    常见的维护方式：Redis维护（无法达到强一致）、MySQL新建一个计数表利用本地事务来维护

    

    